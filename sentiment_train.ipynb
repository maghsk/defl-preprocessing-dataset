{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98907a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.lookup."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfds.load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "337a36ce-385b-4928-828c-12ab7795bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "W2V_SIZE = 300\n",
    "\n",
    "TRAIN_DS_CSV_PATH = 'cleaned_train_ds.csv'\n",
    "TEST_DS_CSV_PATH = 'cleaned_test_ds.csv'\n",
    "W2V_PKL_PATH = 'w2v_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01e2597-cf19-4d0d-8cf7-7e9fbe5fda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DS_CSV_PATH).fillna(\"\")\n",
    "test_df = pd.read_csv(TEST_DS_CSV_PATH).fillna(\"\")\n",
    "w2v_dict = pickle.load(open(W2V_PKL_PATH,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d39995-c1b0-4090-876d-0c847abae7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 288473\n",
      "CPU times: user 13.7 s, sys: 96.5 ms, total: 13.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df.text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d64dc38-9ae2-49ef-a637-283e41f6f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288473, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_dict.keys():\n",
    "        embedding_matrix[i] = w2v_dict[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 283 ms, total: 12.9 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train_df.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test_df.text), maxlen=SEQUENCE_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "y_train = train_df.target.to_numpy().reshape(-1,1) / 4\n",
    "y_test = test_df.target.to_numpy().reshape(-1,1) / 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (1600000, 300)\n",
      "y_train (1600000, 1)\n",
      "\n",
      "x_test (498, 300)\n",
      "y_test (498, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train), tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "test_data = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test), tf.data.Dataset.from_tensor_slices(y_test)))\n",
    "\n",
    "train_data = train_data.shuffle(buffer_size=len(x_train)).batch(BATCH_SIZE).repeat()\n",
    "test_data = test_data.batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50190e07-e54c-4da2-9aa1-6b2bdac5a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(SEQUENCE_LENGTH,)),\n",
    "    tf.keras.layers.Embedding(vocab_size,W2V_SIZE,weights=[embedding_matrix],trainable=False),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e95d931-cbf6-4102-8d42-8f0ea72fd59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 300, 300)          86541900  \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 300, 128)          115328    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 150, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               91600     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,748,929\n",
      "Trainable params: 207,029\n",
      "Non-trainable params: 86,541,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50307e7f-a8d1-4b6e-9806-055d688b7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow_addons as tfa\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tfa.optimizers.AdamW(weight_decay=1e-4),\n",
    "                  # optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])\n",
    "except ImportError:\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867084d3-a4bc-458f-bd57-b674b8016e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5),\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='weights.best.hdf5',save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9faa48-8701-4ac1-acbd-b16c7b43ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 11:49:00.470107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 11:49:02.450694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 11:49:04.014103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7937WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 310s 610ms/step - loss: 0.4428 - accuracy: 0.7937 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8152WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 298s 595ms/step - loss: 0.4058 - accuracy: 0.8152 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8201WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 297s 594ms/step - loss: 0.3974 - accuracy: 0.8201 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8262WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 302s 605ms/step - loss: 0.3863 - accuracy: 0.8262 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8260WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 302s 603ms/step - loss: 0.3858 - accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8276WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 300s 600ms/step - loss: 0.3828 - accuracy: 0.8276 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.8318WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 302s 605ms/step - loss: 0.3758 - accuracy: 0.8318 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8323WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 301s 601ms/step - loss: 0.3738 - accuracy: 0.8323 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.8321WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 301s 602ms/step - loss: 0.3751 - accuracy: 0.8321 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8360WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "500/500 [==============================] - 302s 603ms/step - loss: 0.3686 - accuracy: 0.8360 - lr: 0.0010\n",
      "CPU times: user 7min 37s, sys: 4min 51s, total: 12min 29s\n",
      "Wall time: 50min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_data,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=EPOCHS,\n",
    "                    # batch_size=BATCH_SIZE,\n",
    "                    # epochs=EPOCHS,\n",
    "                    # validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3ebd622-1e85-497f-ba21-17a154574eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 16:04:50.015779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-17 16:04:50.102620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 955ms/step - loss: 0.6152 - accuracy: 0.6004\n",
      "\n",
      "ACCURACY: 0.6004016399383545\n",
      "LOSS: 0.6152105331420898\n",
      "CPU times: user 421 ms, sys: 346 ms, total: 767 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}